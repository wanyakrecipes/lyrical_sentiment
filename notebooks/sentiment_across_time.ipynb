{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da190efe",
   "metadata": {},
   "source": [
    "# Music Lyrics: Sentiment analysis across time\n",
    "\n",
    "Plan\n",
    "1. Clean data and extract sample - need to decide how large the sample is\n",
    "2. Extract common phrases from each track in the sample - this is a proxy for chorus.\n",
    "    * Use gpt-40 mini for this [check pricing] - may need to change model due to api limits\n",
    "    * Use claude-4.5\n",
    "    * Check for if the models pick up the same hooks/common phrases - use cosine similarity and sentence embeddings.\n",
    "3. Extract sentiment of track over time using the following models:\n",
    "    * gpt-40-mini\n",
    "    * bert-trbs\n",
    "    * Use claude-4.5\n",
    "    * consider whether you can smooth charts to show trend\n",
    "4. Extract sentiment of common phrases (proxy for hooks/chorus) using the following models:\n",
    "    * gpt-40-mini\n",
    "    * bert-trbs (to do)\n",
    "    * Use claude-4.5\n",
    "    * consider whether you can smooth charts to show trend\n",
    "5. Write blog and publish on councilsofthefuture.org\n",
    "\n",
    "Could do\n",
    "* Evaluate whether the models have successfully picked up lyrics using LLM as judge\n",
    "    * Could maybe do this by looking at my 50-100 favourite songs, and seeing how well it picks out lyrics?\n",
    "    * would probabaly need ground truth - leave this for the genre bias where you have ground truth of genre?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb19d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Load keys for LLMs\n",
    "load_dotenv()\n",
    "\n",
    "#Initialise aysync clients\n",
    "import asyncio\n",
    "import re\n",
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "from anthropic import AsyncAnthropic\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Initialize async clients\n",
    "openai_client = AsyncOpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "anthropic_client = AsyncAnthropic(api_key = os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "#Added to ensure that it uses the apple M1 cores.\n",
    "#https://github.com/jeffheaton/app_deep_learning/blob/main/install/pytorch-install-aug-2023.ipynb\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "\n",
    "# Automatically use MPS on Mac if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set params\n",
    "\n",
    "#concurrent_\n",
    "#openai_model\n",
    "#claude_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ffa83",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Read data\n",
    "# print(\"Read lyrics data...\")\n",
    "\n",
    "# file_path = '../data/raw/song_lyrics.csv'\n",
    "\n",
    "# chunk_size = 100000\n",
    "\n",
    "# chunks = []\n",
    "\n",
    "# for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "\n",
    "#     chunks.append(chunk)\n",
    "\n",
    "# # Concatenate all chunks into a single DataFrame if needed\n",
    "# print(\"Concact chunks into data frame...\")\n",
    "# song_lyrics_full_df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# #Data Preprocessing using EDA analysis.\n",
    "\n",
    "# #Clean text\n",
    "# def clean_lyrics(text):\n",
    "    \n",
    "#     #Remove text between brackets - this contains META information on verse and chorus - maybe do this seperately.\n",
    "#     text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "#     # Remove newline and tab characters\n",
    "#     text = re.sub(r'[\\n\\t]', ' ', text)\n",
    "    \n",
    "#     # Remove special characters and digits (optional, depending on use case)\n",
    "#     text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    \n",
    "#     # Normalize whitespace\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "#     # Convert to lowercase\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     return text\n",
    "\n",
    "# ### Clean Lyrics ###\n",
    "\n",
    "# #Undertake data cleaning\n",
    "# print(\"Prepare data frame for data cleaning...\")\n",
    "# song_lyrics_clean_df = song_lyrics_full_df.copy()\n",
    "\n",
    "# #Rename tag as genre\n",
    "# print(\"update tag as genre\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df.rename(columns = {\"tag\" : \"genre\"})\n",
    "\n",
    "# #Add track id\n",
    "# print(\"add track_id\")\n",
    "# song_lyrics_clean_df['track_id'] = [str(uuid.uuid4()) for _ in range(len(song_lyrics_clean_df))]\n",
    "\n",
    "# #Filter data for english lyrics\n",
    "# print(\"Filter for English lyrics...\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df[(song_lyrics_clean_df['language'] == 'en')]\n",
    "\n",
    "# #Filter data to remove artists containing \"Genius\"\n",
    "# print(\"Filter to remove artists containing the word 'Genius'\")\n",
    "# song_lyrics_clean_df  = song_lyrics_clean_df [~song_lyrics_clean_df ['artist'].str.contains('Genius', case=False, na=False)]\n",
    "\n",
    "# #Filter for data between 1950 and 2022\n",
    "# print(\"Filter for songs released between 1880 and 2022\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df[(song_lyrics_clean_df['year'] >= 1950) & (song_lyrics_clean_df['year'] <= 2022)]\n",
    "\n",
    "# #Filter data for misc genre\n",
    "# print(\"Remove songs under the misc genre\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df[~(song_lyrics_clean_df['genre'] == 'misc')]\n",
    "\n",
    "# #Filter this population for songs with views more than 95 percentile\n",
    "# print(\"Keep songs with in 95th percentile of views\")\n",
    "# percentile_95 = song_lyrics_clean_df['views'].quantile(0.95)\n",
    "# print(f\"The 95th percentile of views is: {percentile_95}\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df[(song_lyrics_clean_df['views'] >= percentile_95)]\n",
    "\n",
    "# #Clean text - there should really be a clean_lyrics column, not overwrite lyrics.\n",
    "# print(len(song_lyrics_clean_df))\n",
    "# print(\"clean song lyrics\")\n",
    "# song_lyrics_clean_df['clean_lyrics'] = song_lyrics_clean_df['lyrics'].apply(clean_lyrics)\n",
    "\n",
    "# # Drop unecessary columns\n",
    "# print(\"drop columns that are not required\")\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df.drop(columns=['id','language_cld3','language_ft'])\n",
    "\n",
    "# # Column ordering\n",
    "# song_lyrics_clean_df = song_lyrics_clean_df[['track_id','artist','features','title','year','genre','views','language','lyrics','clean_lyrics']]\n",
    "\n",
    "# # save to csv\n",
    "# song_lyrics_clean_df.to_csv(\"../data/processed/song_lyrics_clean_df.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ae779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/f3r19jwn72s9q8h3h8bsc8vh0000gn/T/ipykernel_12804/2822266265.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  song_lyrics_clean_sample_df= song_lyrics_clean_sample_df.groupby('year').apply(lambda x: x.sample(n=2, random_state=2) if len(x) > 2 else x)\n"
     ]
    }
   ],
   "source": [
    "#Read clean dataset (if required)\n",
    "song_lyrics_clean_df = pd.read_csv(\"../data/processed/song_lyrics_clean_df.csv\")\n",
    "\n",
    "#Generate sample for analysis\n",
    "#Select 50 songs per year.\n",
    "song_lyrics_clean_sample_df = song_lyrics_clean_df.copy()\n",
    "#song_lyrics_clean_sample_df= song_lyrics_clean_sample_df.groupby('year').apply(lambda x: x.sample(n=50, random_state=42) if len(x) > 50 else x)\n",
    "song_lyrics_clean_sample_df= song_lyrics_clean_sample_df.groupby('year').apply(lambda x: x.sample(n=2, random_state=2) if len(x) > 2 else x)\n",
    "song_lyrics_clean_sample_df = song_lyrics_clean_sample_df.reset_index(drop=True)\n",
    "\n",
    "#song_lyrics_clean_sample_df = song_lyrics_clean_sample_df.head(5)\n",
    "\n",
    "print(\"Number of samples: \", len(song_lyrics_clean_sample_df))\n",
    "\n",
    "#Graph of distribution of songs per year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde90efa",
   "metadata": {},
   "source": [
    "# 2. Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764bdc2c",
   "metadata": {},
   "source": [
    "## 2.1 Extract sentiment from lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d55c7e",
   "metadata": {},
   "source": [
    "### BERT TRBS\n",
    "\n",
    "Explantion TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e15f8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device,model_name):\n",
    "\n",
    "    MODEL = model_name \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "    return tokenizer, model, labels\n",
    "\n",
    "#Function to classify lyrics\n",
    "def classify_sentiment(text,labels,model,tokenizer,device):\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].cpu().numpy()  # move to CPU for NumPy\n",
    "    return dict(zip(labels, map(float, probs)))\n",
    "\n",
    "#Function for chunking text in case lyrics are longer than 512 tokens\n",
    "def chunk_text(text, tokenizer, max_tokens=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        token_chunk = tokens[i:i + max_tokens]\n",
    "        text_chunk = tokenizer.convert_tokens_to_string(token_chunk)\n",
    "        chunks.append(text_chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def sentiment_over_chunks(lyrics, tokenizer,labels, model, device):\n",
    "    \n",
    "    chunks = chunk_text(lyrics, tokenizer, max_tokens=512)\n",
    "    \n",
    "    all_scores = [classify_sentiment(chunk,labels,model,tokenizer,device) for chunk in chunks]\n",
    "    \n",
    "    # Aggregate: average scores per label\n",
    "    avg_scores = {label: np.mean([score[label] for score in all_scores]) for label in labels}\n",
    "    \n",
    "    # Add label with highest average score\n",
    "    top_label = max(avg_scores, key=avg_scores.get)\n",
    "    \n",
    "    return {\n",
    "        'label': top_label,\n",
    "        'scores': avg_scores\n",
    "    }\n",
    "\n",
    "\n",
    "def collapse_to_binary(label_scores):\n",
    "    if label_scores['positive'] > label_scores['negative']:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f115369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERT-TRBS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lyrical_sentiment/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply senitment over chunks...\n",
      "Extract sentiment labels into new columns...\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer once\n",
    "print(\"Load BERT-TRBS model...\")\n",
    "tokenizer, model, labels = load_model(device = device,\n",
    "                                      model_name = \"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "#Apply sentiment over chunks of \"clean lyrics\"\n",
    "print(\"Apply senitment over chunks...\")\n",
    "song_lyrics_clean_sample_df['sentiment_trbs'] = song_lyrics_clean_sample_df.apply(lambda row: sentiment_over_chunks(lyrics = row['clean_lyrics'],\n",
    "                                                                                                               tokenizer=tokenizer,\n",
    "                                                                                                               labels = labels, \n",
    "                                                                                                               model = model, \n",
    "                                                                                                               device= device), \n",
    "                                                                                                               axis=1)\n",
    "\n",
    "#Extract sentiment into different columns\n",
    "print(\"Extract sentiment labels into new columns...\")\n",
    "song_lyrics_clean_sample_df['sentiment_trbs_label'] = song_lyrics_clean_sample_df['sentiment_trbs'].apply(lambda x: x['label'])\n",
    "song_lyrics_clean_sample_df['sentiment_trbs_positive'] = song_lyrics_clean_sample_df['sentiment_trbs'].apply(lambda x: x['scores']['positive'])\n",
    "song_lyrics_clean_sample_df['sentiment_trbs_negative'] = song_lyrics_clean_sample_df['sentiment_trbs'].apply(lambda x: x['scores']['negative'])\n",
    "song_lyrics_clean_sample_df['sentiment_trbs_neutral'] = song_lyrics_clean_sample_df['sentiment_trbs'].apply(lambda x: x['scores']['neutral'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cdefa8",
   "metadata": {},
   "source": [
    "### Claude and gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8438e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Prompt function (unchanged)\n",
    "def lyrics_sentiment_score_prompt(lyrics):\n",
    "    return f\"\"\"\n",
    "                <role>\n",
    "                You are an expert music critic.\n",
    "                </role>\n",
    "                <task>\n",
    "                Rate the emotional sentiment of the following song lyrics on a scale from -1 (very negative) to 1 (very positive), where 0 is emotionally neutral.\n",
    "                </task>\n",
    "                <instruction>\n",
    "                Only return a single number. No explanation.\n",
    "                </instruction>\n",
    "                <lyrics>\n",
    "\\\"\\\"\\\"\n",
    "{lyrics}\n",
    "\\\"\\\"\\\"\n",
    "                </lyrics>\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "# Cell 3: Async OpenAI function\n",
    "async def get_lyrics_sentiment_score_async(lyrics, model=\"gpt-4o-mini\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Get sentiment score between -1 and 1 from GPT using API (async version).\n",
    "    \"\"\"\n",
    "    prompt = lyrics_sentiment_score_prompt(lyrics=lyrics)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = await openai_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt.strip()},\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            output = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Robust float parsing\n",
    "            match = re.search(r\"-?\\d+(?:\\.\\d+)?\", output)\n",
    "            if match:\n",
    "                return float(match.group())\n",
    "            else:\n",
    "                print(f\"[Warning] Couldn't parse score: {output}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"[Retry {attempt+1}] Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(2)  # Use asyncio.sleep instead of time.sleep\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Cell 4: Async Claude function\n",
    "async def get_lyrics_sentiment_score_claude_async(lyrics, model=\"claude-sonnet-4-5-20250929\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Get sentiment score between -1 and 1 from Claude using API (async version).\n",
    "    \"\"\"\n",
    "    prompt = lyrics_sentiment_score_prompt(lyrics=lyrics)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = await anthropic_client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=1000,\n",
    "                system=\"You are an expert music critic.\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            output = response.content[0].text.strip()\n",
    "            \n",
    "            # Robust float parsing\n",
    "            match = re.search(r\"-?\\d+(?:\\.\\d+)?\", output)\n",
    "            if match:\n",
    "                return float(match.group())\n",
    "            else:\n",
    "                print(f\"[Warning] Couldn't parse score: {output}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"[Retry {attempt+1}] Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(2)  # Use asyncio.sleep instead of time.sleep\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Cell 5: Process all rows with rate limiting\n",
    "async def process_sentiment_scores(df, column='clean_lyrics', max_concurrent=50):\n",
    "    \"\"\"\n",
    "    Process all rows for both OpenAI and Claude with concurrency control.\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def process_openai(lyrics):\n",
    "        async with semaphore:\n",
    "            return await get_lyrics_sentiment_score_async(lyrics)\n",
    "    \n",
    "    async def process_claude(lyrics):\n",
    "        async with semaphore:\n",
    "            return await get_lyrics_sentiment_score_claude_async(lyrics)\n",
    "    \n",
    "    # Create tasks for all rows\n",
    "    print(\"Processing OpenAI sentiment scores...\")\n",
    "    openai_tasks = [process_openai(lyrics) for lyrics in df[column]]\n",
    "    \n",
    "    # Use asyncio.gather to maintain order (preserves row order)\n",
    "    # Wrap with tqdm for progress tracking\n",
    "    openai_results = []\n",
    "    with tqdm(total=len(openai_tasks), desc=\"OpenAI\") as pbar:\n",
    "        for coro in asyncio.as_completed(openai_tasks):\n",
    "            await coro\n",
    "            pbar.update(1)\n",
    "        # Now gather them in order\n",
    "        openai_results = await asyncio.gather(*[process_openai(lyrics) for lyrics in df[column]])\n",
    "    \n",
    "    # Process Claude requests\n",
    "    print(\"\\nProcessing Claude sentiment scores...\")\n",
    "    claude_tasks = [process_claude(lyrics) for lyrics in df[column]]\n",
    "    \n",
    "    # Use asyncio.gather to maintain order (preserves row order)\n",
    "    claude_results = []\n",
    "    with tqdm(total=len(claude_tasks), desc=\"Claude\") as pbar:\n",
    "        for coro in asyncio.as_completed(claude_tasks):\n",
    "            await coro\n",
    "            pbar.update(1)\n",
    "        # Now gather them in order\n",
    "        claude_results = await asyncio.gather(*[process_claude(lyrics) for lyrics in df[column]])\n",
    "    \n",
    "    return openai_results, claude_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254638ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply sentiment scoring...\n",
      "Processing OpenAI sentiment scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe72771f9b840a9adb883196a709dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OpenAI:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Claude sentiment scores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8bdafac6b24deebfe40a173df6549f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Claude:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Complete!\n",
      "OpenAI - Successful: 146\n",
      "OpenAI - Failed: 0\n",
      "Claude - Successful: 146\n",
      "Claude - Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Run the processing\n",
    "print(\"Apply sentiment scoring...\")\n",
    "\n",
    "# Run async processing (use await directly in Jupyter)\n",
    "openai_scores, claude_scores = await process_sentiment_scores(\n",
    "    song_lyrics_clean_sample_df,\n",
    "    column='clean_lyrics',\n",
    "    max_concurrent=50  # Adjust based on your API limits\n",
    ")\n",
    "\n",
    "# Add results to dataframe\n",
    "song_lyrics_clean_sample_df['sentiment_score_gpt_4o_mini'] = openai_scores\n",
    "song_lyrics_clean_sample_df['sentiment_score_claude_4_5'] = claude_scores\n",
    "\n",
    "# Make sure sentiment is numeric\n",
    "song_lyrics_clean_sample_df['sentiment_score_gpt_4o_mini'] = pd.to_numeric(\n",
    "    song_lyrics_clean_sample_df['sentiment_score_gpt_4o_mini'], \n",
    "    errors='coerce'\n",
    ")\n",
    "song_lyrics_clean_sample_df['sentiment_score_claude_4_5'] = pd.to_numeric(\n",
    "    song_lyrics_clean_sample_df['sentiment_score_claude_4_5'], \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Complete!\")\n",
    "print(f\"OpenAI - Successful: {song_lyrics_clean_sample_df['sentiment_score_gpt_4o_mini'].notna().sum()}\")\n",
    "print(f\"OpenAI - Failed: {song_lyrics_clean_sample_df['sentiment_score_gpt_4o_mini'].isna().sum()}\")\n",
    "print(f\"Claude - Successful: {song_lyrics_clean_sample_df['sentiment_score_claude_4_5'].notna().sum()}\")\n",
    "print(f\"Claude - Failed: {song_lyrics_clean_sample_df['sentiment_score_claude_4_5'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f0638",
   "metadata": {},
   "source": [
    "## 2.2 Extract Common Phrases from Lyrics\n",
    "\n",
    "* May need to turn down the temprateure as a couple of the lyrics show thought process - claude\n",
    "* Compare common phrases between models - check for degree of agreement/disagreement.\n",
    "* Use an LLM to evaluate that the lyrics extracted feature in the actual lyrics\n",
    "* Could do with a dataset where I extract the hook for a song, and see if it turns up as one of the key phrases.\n",
    "* Maybe do this on a sample of the sample? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202e04a",
   "metadata": {},
   "source": [
    "### Extract using claude and gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b1eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prompt function (unchanged)\n",
    "def phrase_extraction_prompt(lyrics):\n",
    "    return f\"\"\"\n",
    "You are a helpful music analyst.\n",
    "From the following song lyrics, extract the top 3 most frequently repeated *phrases*.\n",
    "A phrase is any sequence of words that appears on a new line.\n",
    "Ignore case and punctuation. Return only the 3 most frequent phrases.\n",
    "Do not return any reasoning or thought process.\n",
    "Respond in the following XML format:\n",
    "<phrases>\n",
    "<phrase>...</phrase>\n",
    "<phrase>...</phrase>\n",
    "<phrase>...</phrase>\n",
    "</phrases>\n",
    "Lyrics:\n",
    "\\\"\\\"\\\"\n",
    "{lyrics}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# Step 2: Async OpenAI function\n",
    "async def get_common_phrases_from_lyrics_async(lyrics, model=\"gpt-5-nano\"):\n",
    "    \"\"\"\n",
    "    Get common lyrics from GPT using an OpenAI model (async version).\n",
    "    \"\"\"\n",
    "    prompt = phrase_extraction_prompt(lyrics)\n",
    "    response = await openai_client.responses.create(\n",
    "        model=model,\n",
    "        input = prompt\n",
    "    )\n",
    "    return response.output_text.strip()\n",
    "\n",
    "\n",
    "# Step 3: Async Claude function\n",
    "async def get_common_phrases_from_lyrics_claude_async(lyrics, model=\"claude-sonnet-4-5-20250929\"):\n",
    "    \"\"\"\n",
    "    Get common lyrics from Claude (async version).\n",
    "    \"\"\"\n",
    "    prompt = phrase_extraction_prompt(lyrics)\n",
    "    response = await anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1000,\n",
    "        system=\"You analyze song lyrics.\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "# Step 4: Process all rows with concurrency control\n",
    "async def process_all_rows(df, max_concurrent=50):\n",
    "    \"\"\"\n",
    "    Process all rows with both OpenAI and Claude, with concurrency control.\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def process_row_openai(lyrics):\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                return await get_common_phrases_from_lyrics_async(lyrics)\n",
    "            except Exception as e:\n",
    "                print(f\"OpenAI error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    async def process_row_claude(lyrics):\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                return await get_common_phrases_from_lyrics_claude_async(lyrics)\n",
    "            except Exception as e:\n",
    "                print(f\"Claude error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    # Create tasks for all rows\n",
    "    openai_tasks = [process_row_openai(lyrics) for lyrics in df['lyrics']]\n",
    "    claude_tasks = [process_row_claude(lyrics) for lyrics in df['lyrics']]\n",
    "    \n",
    "    # Process OpenAI requests - use gather to maintain order\n",
    "    print(\"Processing OpenAI requests...\")\n",
    "    openai_results = await asyncio.gather(*openai_tasks)\n",
    "    print(f\"✓ Completed {len(openai_results)} OpenAI requests\")\n",
    "    \n",
    "    # Process Claude requests - use gather to maintain order\n",
    "    print(\"\\nProcessing Claude requests...\")\n",
    "    claude_results = await asyncio.gather(*claude_tasks)\n",
    "    print(f\"✓ Completed {len(claude_results)} Claude requests\")\n",
    "    \n",
    "    return openai_results, claude_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e7376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract top three common phrases...\n",
      "Processing OpenAI requests...\n",
      "✓ Completed 146 OpenAI requests\n",
      "\n",
      "Processing Claude requests...\n",
      "✓ Completed 146 Claude requests\n",
      "\n",
      "✓ Complete!\n",
      "OpenAI successful: 146/146\n",
      "Claude successful: 146/146\n"
     ]
    }
   ],
   "source": [
    "# Run the async processing\n",
    "print(\"Extract top three common phrases...\")\n",
    "\n",
    "# Run async processing (use await directly in Jupyter)\n",
    "openai_results, claude_results = await process_all_rows(\n",
    "    song_lyrics_clean_sample_df, \n",
    "    max_concurrent=50  # Adjust based on your API limits\n",
    ")\n",
    "\n",
    "# Add results to dataframe\n",
    "song_lyrics_clean_sample_df['common_phrases_gpt_4o_mini'] = openai_results\n",
    "song_lyrics_clean_sample_df['common_phrases_claude_4_5'] = claude_results\n",
    "\n",
    "print(\"\\n✓ Complete!\")\n",
    "print(f\"OpenAI successful: {sum(1 for r in openai_results if r is not None)}/{len(openai_results)}\")\n",
    "print(f\"Claude successful: {sum(1 for r in claude_results if r is not None)}/{len(claude_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c81347",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daa377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For claude model\n",
    "def extract_phrases_from_xml(xml_string):\n",
    "    \"\"\"\n",
    "    Extracts phrases from XML format and returns them as a list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle None or empty values\n",
    "        if pd.isna(xml_string) or xml_string == '':\n",
    "            return []\n",
    "        \n",
    "        # Parse the XML string\n",
    "        root = ET.fromstring(xml_string)\n",
    "        \n",
    "        # Extract all phrase texts\n",
    "        phrases = [phrase.text for phrase in root.findall('phrase') if phrase.text]\n",
    "        \n",
    "        return phrases\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        return []\n",
    "\n",
    "#for gpt model\n",
    "def extract_phrases_from_xml_md(xml_string):\n",
    "    \"\"\"\n",
    "    Extracts phrases from XML format and returns them as a list.\n",
    "    Handles markdown code blocks (```xml ... ```)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle None or empty values\n",
    "        if pd.isna(xml_string) or xml_string == '':\n",
    "            return []\n",
    "        \n",
    "        # Remove markdown code block markers\n",
    "        xml_string = xml_string.strip()\n",
    "        if xml_string.startswith('```xml'):\n",
    "            xml_string = xml_string[6:]  # Remove ```xml\n",
    "        if xml_string.startswith('```'):\n",
    "            xml_string = xml_string[3:]  # Remove ``` (in case it's just ```)\n",
    "        if xml_string.endswith('```'):\n",
    "            xml_string = xml_string[:-3]  # Remove closing ```\n",
    "        \n",
    "        xml_string = xml_string.strip()\n",
    "        \n",
    "        # Parse the XML string\n",
    "        root = ET.fromstring(xml_string)\n",
    "        \n",
    "        # Extract all phrase texts\n",
    "        phrases = [phrase.text for phrase in root.findall('phrase') if phrase.text]\n",
    "        \n",
    "        return phrases\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        print(f\"Problematic string: {xml_string[:100]}\")  # Print first 100 chars for debugging\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31cdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n",
      "Error parsing XML: not well-formed (invalid token): line 2, column 30\n",
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n",
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n",
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n",
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n",
      "Error parsing XML: not well-formed (invalid token): line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "# Clean data from LLM\n",
    "# claude\n",
    "song_lyrics_clean_sample_df['common_phrases_claude_4_5_list'] = song_lyrics_clean_sample_df['common_phrases_claude_4_5'].apply(extract_phrases_from_xml)\n",
    "\n",
    "# gpt\n",
    "song_lyrics_clean_sample_df['common_phrases_gpt_4o_mini_list'] = song_lyrics_clean_sample_df['common_phrases_gpt_4o_mini'].apply(extract_phrases_from_xml_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaab661",
   "metadata": {},
   "source": [
    "## 2.3 Extract Sentiment of Common Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce484d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt function (unchanged)\n",
    "def phrase_sentiment_prompt(xml_phrases):\n",
    "    return f\"\"\"\n",
    "            You are an expert sentiment analyst.\n",
    "            Given a list of phrases from music lyrics in XML format, return a emotional sentiment score for each phrase.\n",
    "            Each score must be a number between -1 and 1, where:\n",
    "            -1 = very negative, 0 = emotionally neutral, 1 = very positive.\n",
    "            Respond in the following XML format:\n",
    "            <phrase_sentiments>\n",
    "            <phrase text=\"...\">[sentiment_score]</phrase>\n",
    "            ...\n",
    "            </phrase_sentiments>\n",
    "            Here is the list of phrases:\n",
    "{xml_phrases}\n",
    "            \"\"\".strip()\n",
    "\n",
    "\n",
    "# Parsing function (unchanged)\n",
    "def parse_phrase_sentiment_scores(xml_text):\n",
    "    try:\n",
    "        return [(phrase, float(score)) for phrase, score in re.findall(r'<phrase text=\"(.*?)\">(.*?)</phrase>', xml_text)]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "# Async OpenAI function\n",
    "async def get_phrase_sentiment_scores_async(xml_phrases, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Get sentiment of common lyrics from GPT using an OpenAI model (async version).\n",
    "    \"\"\"\n",
    "    prompt = phrase_sentiment_prompt(xml_phrases)\n",
    "    response = await openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You analyze sentiment of music lyrics with numeric scores.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Async Claude function\n",
    "async def get_phrase_sentiment_scores_claude_async(xml_phrases, model=\"claude-sonnet-4-5-20250929\"):\n",
    "    \"\"\"\n",
    "    Get sentiment of common lyrics from Claude (async version).\n",
    "    \"\"\"\n",
    "    prompt = phrase_sentiment_prompt(xml_phrases)\n",
    "    response = await anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1000,\n",
    "        system=\"You analyze sentiment of music lyrics with numeric scores\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "\n",
    "# Process all rows with concurrency control\n",
    "async def process_phrase_sentiments(df, max_concurrent=50):\n",
    "    \"\"\"\n",
    "    Process all rows for phrase sentiment analysis with both OpenAI and Claude.\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def process_openai(xml_phrases):\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                return await get_phrase_sentiment_scores_async(xml_phrases)\n",
    "            except Exception as e:\n",
    "                print(f\"OpenAI error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    async def process_claude(xml_phrases):\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                return await get_phrase_sentiment_scores_claude_async(xml_phrases)\n",
    "            except Exception as e:\n",
    "                print(f\"Claude error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    # Create tasks for all rows\n",
    "    print(\"Processing OpenAI phrase sentiment requests...\")\n",
    "    openai_tasks = [process_openai(phrases) for phrases in df['common_phrases_gpt_4o_mini']]\n",
    "    openai_results = await asyncio.gather(*openai_tasks)\n",
    "    print(f\"✓ Completed {len(openai_results)} OpenAI requests\")\n",
    "    \n",
    "    print(\"\\nProcessing Claude phrase sentiment requests...\")\n",
    "    claude_tasks = [process_claude(phrases) for phrases in df['common_phrases_claude_4_5']]\n",
    "    claude_results = await asyncio.gather(*claude_tasks)\n",
    "    print(f\"✓ Completed {len(claude_results)} Claude requests\")\n",
    "    \n",
    "    return openai_results, claude_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the async processing\n",
    "print(\"Getting phrase sentiment scores...\")\n",
    "\n",
    "# Run async processing (use await directly in Jupyter)\n",
    "openai_sentiment_results, claude_sentiment_results = await process_phrase_sentiments(\n",
    "    song_lyrics_clean_sample_df,\n",
    "    max_concurrent=50  # Adjust based on your API limits\n",
    ")\n",
    "\n",
    "# Add results to dataframe\n",
    "song_lyrics_clean_sample_df['common_phrases_sentiment_gpt_4o_mini'] = openai_sentiment_results\n",
    "song_lyrics_clean_sample_df['common_phrases_sentiment_claude_4_5'] = claude_sentiment_results\n",
    "\n",
    "print(\"\\nParse sentiment from xml......\")\n",
    "song_lyrics_clean_sample_df['common_phrases_sentiment_gpt_4o_mini'] = song_lyrics_clean_sample_df['common_phrases_sentiment_gpt_4o_mini'].apply(parse_phrase_sentiment_scores)\n",
    "song_lyrics_clean_sample_df['common_phrases_sentiment_claude_4_5'] = song_lyrics_clean_sample_df['common_phrases_sentiment_claude_4_5'].apply(parse_phrase_sentiment_scores)\n",
    "\n",
    "print(\"Calculate average sentiment...\")\n",
    "song_lyrics_clean_sample_df['common_phrases_average_sentiment_gpt_4o_mini'] = song_lyrics_clean_sample_df['common_phrases_sentiment_gpt_4o_mini'].apply(\n",
    "    lambda lst: round(sum(score for _, score in lst) / len(lst), 3) if lst else None\n",
    ")\n",
    "song_lyrics_clean_sample_df['common_phrases_average_sentiment_claude_4_5'] = song_lyrics_clean_sample_df['common_phrases_sentiment_claude_4_5'].apply(\n",
    "    lambda lst: round(sum(score for _, score in lst) / len(lst), 3) if lst else None\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Complete!\")\n",
    "print(f\"OpenAI successful: {sum(1 for r in openai_sentiment_results if r is not None)}/{len(openai_sentiment_results)}\")\n",
    "print(f\"Claude successful: {sum(1 for r in claude_sentiment_results if r is not None)}/{len(claude_sentiment_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2cffd",
   "metadata": {},
   "source": [
    "# 3. Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51410e89",
   "metadata": {},
   "source": [
    "## 3.1 Lyrical sentiment across time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440ea02",
   "metadata": {},
   "source": [
    "### BERT TRBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7298a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate graph of sentiment over time\n",
    "trbs_positive_sentiment_per_year_plt = song_lyrics_clean_sample_df.groupby('year')['sentiment_trbs_positive'].mean().plot(title=\"Positive sentiment of songs TBC (n=\" + str(len(song_lyrics_clean_sample_df)) +\",bert-trbs)\",\n",
    "                                                                                                                    ylabel=\"Average positive sentiment\")\n",
    "\n",
    "\n",
    "trbs_neutral_sentiment_per_year_plt = song_lyrics_clean_sample_df.groupby('year')['sentiment_trbs_neutral'].mean().plot(title=\"Neutral sentiment of songs TBC (n=\" + str(len(song_lyrics_clean_sample_df)) +\",bert-trbs)\",\n",
    "                                                                                                                     ylabel=\"Average neutral sentiment\")\n",
    "\n",
    "\n",
    "trbs_negative_sentiment_per_year_plt = song_lyrics_clean_sample_df.groupby('year')['sentiment_trbs_negative'].mean().plot(title=\"Negative sentiment of songs TBC (n=\" + str(len(song_lyrics_clean_sample_df)) +\",bert-trbs)\",\n",
    "                                                                                                                     ylabel=\"Average negative sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb87245",
   "metadata": {},
   "source": [
    "### gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year\n",
    "yearly_sentiment_gpt_plt = song_lyrics_clean_sample_df.groupby('year')['sentiment_score_gpt_4o_mini'].mean().plot(title=\"Average sentiment of song lyrics TBC (n=\" + str(len(song_lyrics_clean_sample_df)) +\",gpt-4o-mini)\",\n",
    "                                                                                                          ylabel=\"Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308345af",
   "metadata": {},
   "source": [
    "### claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf219ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year\n",
    "yearly_sentiment_claude_plt = song_lyrics_clean_sample_df.groupby('year')['sentiment_score_claude_4_5'].mean().plot(title=\"Average sentiment of song lyrics TBC (n=\" + str(len(song_lyrics_clean_sample_df)) +\",claude)\",\n",
    "                                                                                                                ylabel=\"Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ecf98",
   "metadata": {},
   "source": [
    "## 3.2 Comparing common phrases extraction between LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e61841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run cosine similairty \n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "cosine_similarity_df = song_lyrics_clean_sample_df[['track_id','common_phrases_gpt_4o_mini_list','common_phrases_claude_4_5_list']]\n",
    "\n",
    "# Remove rows where either column has an empty list\n",
    "cosine_similarity_df  = cosine_similarity_df [(cosine_similarity_df ['common_phrases_gpt_4o_mini_list'].str.len() > 0) & \n",
    "                                              (cosine_similarity_df ['common_phrases_claude_4_5_list'].str.len() > 0)]\n",
    "\n",
    "\n",
    "# Join phrases with spaces\n",
    "cosine_similarity_df ['common_phrases_gpt_4o_mini_combined'] = cosine_similarity_df ['common_phrases_gpt_4o_mini_list'].apply(lambda x: ' '.join(x))\n",
    "cosine_similarity_df ['common_phrases_claude_4_5_combined'] = cosine_similarity_df ['common_phrases_claude_4_5_list'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Calculate embeddings\n",
    "cosine_similarity_df ['common_phrases_gpt_4o_mini_embeddings'] = cosine_similarity_df ['common_phrases_gpt_4o_mini_combined'].apply(lambda x: model.encode(x))\n",
    "cosine_similarity_df ['common_phrases_claude_4_5_embeddings'] = cosine_similarity_df ['common_phrases_claude_4_5_combined'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Calculate similarity as before\n",
    "def calculate_row_similarity(row):\n",
    "    emb1 = row['common_phrases_gpt_4o_mini_embeddings'].reshape(1, -1)\n",
    "    emb2 = row['common_phrases_claude_4_5_embeddings'].reshape(1, -1)\n",
    "    return cosine_similarity(emb1, emb2)[0][0]\n",
    "\n",
    "cosine_similarity_df['similarity_score'] = cosine_similarity_df.apply(calculate_row_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76dc3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise results with hisotgram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cosine_similarity_df['similarity_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Similarity Scores Between LLM1 and LLM2')\n",
    "plt.axvline(cosine_similarity_df['similarity_score'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {cosine_similarity_df[\"similarity_score\"].mean():.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise results with KDE plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=cosine_similarity_df['similarity_score'], fill=True)\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of Similarity Scores')\n",
    "plt.axvline(cosine_similarity_df['similarity_score'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {cosine_similarity_df[\"similarity_score\"].mean():.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d9376",
   "metadata": {},
   "source": [
    "## 3.3 Common phrases sentiment across time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa773b",
   "metadata": {},
   "source": [
    "### gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53416057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate graph of sentiment over time\n",
    "print(\"Generate sentiment over time...\")\n",
    "common_phrases_sentiment_per_year_gpt_plt = song_lyrics_clean_sample_df.groupby('year')['common_phrases_average_sentiment_gpt_4o_mini'].mean().plot(title=\"TBC common phrases (n=\" + str(len(song_lyrics_clean_sample_df)) +\",gpt-4o-mini)\",\n",
    "                                                                                                                                   ylabel=\"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a817c06",
   "metadata": {},
   "source": [
    "### claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate graph of sentiment over time\n",
    "print(\"Generate sentiment over time...\")\n",
    "common_phrases_sentiment_per_year_claude_plt = song_lyrics_clean_sample_df.groupby('year')['common_phrases_average_sentiment_claude_4_5'].mean().plot(title=\"TBC common phrases (n=\" + str(len(song_lyrics_clean_sample_df)) +\",claude-4-5)\",\n",
    "                                                                                                                                              ylabel=\"sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyrical_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
